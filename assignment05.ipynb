{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "05526988a9a559e57a37a26d6d98a1a9",
     "grade": false,
     "grade_id": "cell-40f64c0268613244",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 5: Mining Sequence Data\n",
    "\n",
    "In this assignment, we will explore the sequence representation of data. Lots of real-world data can be represented as sequences. Among them, text data is typical and widely available, which we will use for this assignment. We will look at the Tweets with the colorful emojis again, but this time we are not going to filter the  textual content. Several toolkits or packages have been developed to process text data. In this assignment, we will rely on the [NLTK](https://www.nltk.org/) package (Natual Language Toolkit).\n",
    "\n",
    "In this assignment, you will: \n",
    "* Tokenize text data and extract ngrams and skip-grams.\n",
    "* Finding near-duplicate sequences of a given piece of text.  \n",
    "\n",
    "First, let's load the dependencies and the Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "024c36dc5f933ad0e192be4f64756758",
     "grade": false,
     "grade_id": "cell-3883ecbd0f3cfad0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import nltk\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "823ad79d7ca888f0fca14a06a089d470",
     "grade": false,
     "grade_id": "cell-ad2e286473e795bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"RT @stunnaboyco: @LUSCIOUSLOUIS that's lunchtime 🍩🍫🍫🍨 rite there 👍👍👍👏😊😊😍😍😗 https://t.co/m0Wngznctw\",\n",
       " '@RossoRestaurant looking forward to joining you for lunch tomorrow to celebrate my husbands birthday! 🎂🥂',\n",
       " 'Out wth my lilbro 4 ice-cream🍡🍦🍦🍦 https://t.co/dFEimQiF3n',\n",
       " 'Kuku🍑 le Dickson🍆 tsa ba bangwe di behaviour okare Clientelle funeral cover They can cover up to 15 guys/ladies. #TheLivingSoul👴',\n",
       " 'RT @Thabang92416252: \"@PinexAndApplex: 🍍🍏 @EmteeSA - We up🔥 https://t.co/nGbvFW2CUA\"YEE']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "with open('more_tweets.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if len(line) > 0:\n",
    "            tweets.append(line.strip())\n",
    "tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fea13200b5a091da0379f7c05255780f",
     "grade": false,
     "grade_id": "cell-06949c03757d6cae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To construct the sequence representation of the Tweet, we need to tokenize each Tweet into a sequence of language units, which in our case are words. For this assignment, we will use the TweetTokenizer API. For some languages, however, tokenization can be challenging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a763c758b059f261060b28e4f4d5d5f",
     "grade": false,
     "grade_id": "cell-85f395369e713527",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.casual.TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe34b0d4ea4828ca2dc87f5ed878c4a0",
     "grade": false,
     "grade_id": "cell-2ca6e08c67060260",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " '@stunnaboyco',\n",
       " ':',\n",
       " '@LUSCIOUSLOUIS',\n",
       " \"that's\",\n",
       " 'lunchtime',\n",
       " '🍩',\n",
       " '🍫',\n",
       " '🍫',\n",
       " '🍨',\n",
       " 'rite',\n",
       " 'there',\n",
       " '👍',\n",
       " '👍',\n",
       " '👍',\n",
       " '👏',\n",
       " '😊',\n",
       " '😊',\n",
       " '😍',\n",
       " '😍',\n",
       " '😗',\n",
       " 'https://t.co/m0Wngznctw']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(tweets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0152bce7d0307019c9a7a4686db34352",
     "grade": false,
     "grade_id": "cell-634c84b8ac40331b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For a quick sanity check, we can calculate the word frequency and see which ones are the most frequently used. With the Counter object, we can easily obtain the most frequently used words and their numbers of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "940600a9af2e4b7ac48f8425c263b7ea",
     "grade": false,
     "grade_id": "cell-6e7d9a6906d635db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 4748),\n",
       " (':', 4601),\n",
       " ('RT', 3759),\n",
       " ('️', 3011),\n",
       " ('…', 2711),\n",
       " ('.', 2409),\n",
       " ('🎂', 2135),\n",
       " (',', 2083),\n",
       " ('a', 1830),\n",
       " ('to', 1819),\n",
       " ('the', 1806),\n",
       " ('you', 1670),\n",
       " ('and', 1647),\n",
       " ('🍾', 1413),\n",
       " ('I', 1404),\n",
       " ('🎉', 1294),\n",
       " ('🥂', 1274),\n",
       " ('Happy', 1270),\n",
       " ('🍰', 1226),\n",
       " ('🍻', 1183)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_counter = Counter()\n",
    "for tweet in tweets:\n",
    "    unigram_list = tokenizer.tokenize(tweet)\n",
    "    unigram_counter.update(unigram_list)\n",
    "unigram_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3bf03d6d9f184e705a3fdfa756c1f8b7",
     "grade": false,
     "grade_id": "cell-61814a39523457fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "One common type of defined sequential patterns are $n$-grams. Particularly, 1-grams are often called \"unigrams\", 2-grams called bigrams, and 3-grams trigrams. Let's examine the bigrams of a Tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe30acd62628c484dddcb6c159d43ee7",
     "grade": false,
     "grade_id": "cell-9a63cf1c82603cf8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RT', '@stunnaboyco'),\n",
       " ('@stunnaboyco', ':'),\n",
       " (':', '@LUSCIOUSLOUIS'),\n",
       " ('@LUSCIOUSLOUIS', \"that's\"),\n",
       " (\"that's\", 'lunchtime'),\n",
       " ('lunchtime', '🍩'),\n",
       " ('🍩', '🍫'),\n",
       " ('🍫', '🍫'),\n",
       " ('🍫', '🍨'),\n",
       " ('🍨', 'rite'),\n",
       " ('rite', 'there'),\n",
       " ('there', '👍'),\n",
       " ('👍', '👍'),\n",
       " ('👍', '👍'),\n",
       " ('👍', '👏'),\n",
       " ('👏', '😊'),\n",
       " ('😊', '😊'),\n",
       " ('😊', '😍'),\n",
       " ('😍', '😍'),\n",
       " ('😍', '😗'),\n",
       " ('😗', 'https://t.co/m0Wngznctw')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_list = list(nltk.bigrams(tokenizer.tokenize(tweets[0])))\n",
    "bigram_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fab7995160ec4d261a72d0c4591b227c",
     "grade": false,
     "grade_id": "cell-a358a9406182fc78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that each bigram is represented as a tuple of two strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10828d8ef62c19a46044d54b3ec86b70",
     "grade": false,
     "grade_id": "cell-7e3d9f67e0213759",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1. Find the most frequent bigrams (1.5 pts)\n",
    "\n",
    "Please complete the `freq_bigram` function to find the $n$ most frequent bigrams. Your function should return a list of `top_n` tuples, each of the tuples should contain a bigram tuple (such as ('👍', '👏')) and its number of occurrence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e95e4b9e609f1fd83ff13b711580cb89",
     "grade": false,
     "grade_id": "cell-c1116778c8dfe183",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def freq_bigrams(tweets, top_n):\n",
    "    bigram_counter = Counter()\n",
    "    for tweet in tweets:\n",
    "        # YOUR CODE HERE\n",
    "        bigram_list = list(nltk.bigrams(tokenizer.tokenize(tweet)))\n",
    "        bigram_counter.update(bigram_list)\n",
    "    return bigram_counter.most_common(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('!', '!'), 1334),\n",
       " (('❤', '️'), 624),\n",
       " (('Happy', 'Birthday'), 570),\n",
       " (('’', 's'), 483),\n",
       " (('☕', '️'), 450),\n",
       " (('Happy', 'birthday'), 347),\n",
       " (('🍾', '🥂'), 288),\n",
       " (('🎂', '🎂'), 277),\n",
       " (('🎂', '🍰'), 276),\n",
       " (('☀', '️'), 274)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_bigrams(tweets, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5dcee4564f2ceb00a8a1f4684dc955c",
     "grade": true,
     "grade_id": "cell-8aaf916693fdac5c",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "# This test cell contains hidden tests. Passing the displayed assertions does not guarant full points.\n",
    "answer = freq_bigrams(tweets, 10)\n",
    "assert answer[0] == (('!', '!'), 1334)\n",
    "\n",
    "answer2 = freq_bigrams(tweets, 6)\n",
    "assert len(answer2) == 6\n",
    "assert answer2[5] == (('Happy', 'birthday'), 347)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8265ded396050c66ded5fdd83d71287",
     "grade": false,
     "grade_id": "cell-9e105411817a7835",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Similarly, you can generate trigrams by calling the `nltk.trigrams` API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9cba2d268d95ce41937c573dc29df128",
     "grade": false,
     "grade_id": "cell-7970a41d638fe9ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2. Find the most frequent skipgrams (1 pt)\n",
    "\n",
    "In this exercise we will compute another commonly defined type of sequential patterns -- the skip-grams. Luckily this is also supported by NLTK. You can find the documentation [here](https://tedboy.github.io/nlps/generated/generated/nltk.skipgrams.html).\n",
    "\n",
    "Please implement the `freq_skipgrams` function to calculate the most frequently used $k$-skip-$n$-grams. Your function should return a list of `top_n` tuples, each of the tuples should contain a $k$-skip-$n$-gram tuple (such as ('Happy', 'Birthday', '🎂')) and its number of occurrences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2516dfc27709864d28ddbdf06ce5f123",
     "grade": false,
     "grade_id": "cell-dd5f5da07000fdc8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def freq_skipgrams(tweets, n, k, top_n):\n",
    "    skipgram_counter = Counter()\n",
    "    # YOUR CODE HERE\n",
    "    for tweet in tweets:\n",
    "        skipgram_list = list(nltk.skipgrams(tokenizer.tokenize(tweet), n, k))\n",
    "        skipgram_counter.update(skipgram_list)\n",
    "    return skipgram_counter.most_common(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('!', '!'), 1334),\n",
       " (('❤', '️'), 624),\n",
       " (('Happy', 'Birthday'), 570),\n",
       " (('’', 's'), 483),\n",
       " (('☕', '️'), 450),\n",
       " (('Happy', 'birthday'), 347),\n",
       " (('🍾', '🥂'), 288),\n",
       " (('🎂', '🎂'), 277),\n",
       " (('🎂', '🍰'), 276),\n",
       " (('☀', '️'), 274)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_bigrams(tweets, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c0c850cc6078905062e9a20afd434cd",
     "grade": true,
     "grade_id": "cell-404194a7b8c6d451",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "answer = freq_skipgrams(tweets, n=3, k=2, top_n=10)\n",
    "assert answer[0] == (('!', '!', '!'), 511)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a87baccc4cb6b45ff1a2d1f4716957d",
     "grade": false,
     "grade_id": "cell-d9450f9b8cfa8258",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Ngrams and skipgrams are commonly used in text mining, biological sequence mining, and behavior mining tasks. They are directly used as basis for tasks like phrase detection, named-entity detection, and motif detection, and they are also used as features for building machine learning models in general. Have fun using them in your own data analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "439ea221bf3ab70bb2a7e0e66023cab3",
     "grade": false,
     "grade_id": "cell-fa5dd9813b92f313",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Detecting Near Duplicates\n",
    "\n",
    "Sequence similarity metrics can be widely applied to many tasks. In this part of the assignment, let's look at an application of sequence similarity -- detecting near-duplicates.  Near-duplicate detection is commonly used in plagiarism detection, index selection for search engines, copy-paste detection, biological sequence alignments, and beyond. Following the introduction of *shingling* in the lecture, let's practice it on our Twitter dataset. The *shingling* approach relies on $n$-grams and Jaccard similarity. Luckily, we have already been familiar with both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f8d9a8f24d84bb00e52249e9f13fed9",
     "grade": false,
     "grade_id": "cell-5c8f8934c3eedddd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3. Shingling (1.5 pts)\n",
    "\n",
    "Complete the `shingling_jaccard_similarity` function to compute the similarity score between two pieces of text using the shingling approach. Specifically, you should (1) represent both text sequences as sets of overlapping $n$-grams ($n$ specified as an argument) and (2) compute the Jaccard similarity between the two sets. We have implemented a `jaccard_similarity` function for your convenience. \n",
    "\n",
    "**Hint**: \n",
    "1. You may use the `nltk.ngrams` API to obtain the $n$-grams. \n",
    "2. The `nltk.ngrams` API returns a iterator of tuples. you may wrap it up with `list()` to collect the $n$-grams as a list. You may checkout how we use `nltk.bigrams` in the beginning of this assignment as example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89ff7b92b33dd9e77aa1f47073902b2b",
     "grade": false,
     "grade_id": "cell-6460a982dc84bc93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity(list_x, list_y):\n",
    "    set_x = set(list_x)\n",
    "    set_y = set(list_y)\n",
    "    intersection = set_x.intersection(set_y)\n",
    "    union = set_x.union(set_y)\n",
    "    return len(intersection) / len(union) if len(union) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "edff56b6b09307e5754cf6495cfbdce0",
     "grade": false,
     "grade_id": "cell-0bcf1d6f6aed2733",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.casual.TweetTokenizer()\n",
    "def shingling_jaccard_similarity(text_x, text_y, n):\n",
    "    # YOUR CODE HERE\n",
    "    ngram_list1 = list(nltk.ngrams(tokenizer.tokenize(text_x), n))\n",
    "    ngram_list = list(nltk.ngrams(tokenizer.tokenize(text_y), n))\n",
    "    sim_score = jaccard_similarity(ngram_list1, ngram_list)\n",
    "    return sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "x = \"to be or not to be\"\n",
    "y = \"not be or not to be\"\n",
    "z = \"be or not to not be\"\n",
    "\n",
    "print(shingling_jaccard_similarity(x,y, 3))\n",
    "print(shingling_jaccard_similarity(x,z, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56497ebb22a915ec79abf6b649c5eca4",
     "grade": true,
     "grade_id": "cell-5976f57480088624",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert abs(shingling_jaccard_similarity(\"to be or not to be\", \"not be or not to be\", 3) - 0.6) < 1e-8\n",
    "assert abs(shingling_jaccard_similarity(\"to be or not to be\", \"be or not to not be\", 3) - 1/3) < 1e-8\n",
    "\n",
    "assert abs(shingling_jaccard_similarity(\"a b c a b\", \"a b c a b c a b c\", 3) - 1) < 1e-8\n",
    "assert abs(shingling_jaccard_similarity(\"a a a b b b c c c\", \"a b c a b c\", 2) - 1/3) < 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "331dc56d970d8183aea24de043ff7249",
     "grade": false,
     "grade_id": "cell-cf0eb9f87a032dc6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's see how this similarity function can help us detect near-duplicating tweets in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0785fd76de0d5ffb39b28d08706218cb",
     "grade": false,
     "grade_id": "cell-2c2ba5471c82ee4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv(\"more_tweets.txt\", sep=\"\\t\", header=None)\n",
    "tweet_df.columns = ['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a31e0e6132debe92868252788ee66cb",
     "grade": false,
     "grade_id": "cell-5003383e6882b1cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "One of the Tweet that caught our attention has the index of 220."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "022277e2595c38d2d6646384b977165b",
     "grade": false,
     "grade_id": "cell-61ed470985b51e32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#TopListAngels 👠 Ready For BO 👠 🍭 @malangangels 🍭 🍸 Malang 🍸 💰 dan ☎ by DM https://t.co/vS1Oukm3yq\n"
     ]
    }
   ],
   "source": [
    "print(tweet_df.loc[220].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c942c7ea3657f8a2eaf2f74180f7f304",
     "grade": false,
     "grade_id": "cell-53ad58fa0b0fdd7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's see whether we can find near duplicates of this Tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69cc85c512ab546405b51e180fc187a9",
     "grade": false,
     "grade_id": "cell-a3ddad870d7a4a12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>#TopListAngels 👠 Ready For BO 👠 🍭 @malangangel...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4906</th>\n",
       "      <td>RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭...</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭...</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>#TopListAngels 👠 Ready For BO 👠 🍭 @VaniaBDG_2 ...</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6109</th>\n",
       "      <td>#TopListAngels 👠 Ready For BO 👠 🍭 @Lanci_Mevit...</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭...</td>\n",
       "      <td>0.346154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭...</td>\n",
       "      <td>0.346154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6575</th>\n",
       "      <td>Case of the Monday Blues? Nothing a KNOW Bette...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6577</th>\n",
       "      <td>RT @LunnMiss: #TwinPeaks 🌲🦉🌲 «Fire Walk With M...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text       sim\n",
       "220   #TopListAngels 👠 Ready For BO 👠 🍭 @malangangel...  1.000000\n",
       "2342  RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭...  0.750000\n",
       "4906  RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭...  0.521739\n",
       "2280  RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭...  0.521739\n",
       "2323  #TopListAngels 👠 Ready For BO 👠 🍭 @VaniaBDG_2 ...  0.391304\n",
       "6109  #TopListAngels 👠 Ready For BO 👠 🍭 @Lanci_Mevit...  0.375000\n",
       "3651  RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭...  0.346154\n",
       "5118  RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭...  0.346154\n",
       "6575  Case of the Monday Blues? Nothing a KNOW Bette...  0.000000\n",
       "6577  RT @LunnMiss: #TwinPeaks 🌲🦉🌲 «Fire Walk With M...  0.000000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df['sim'] = tweet_df.text.apply(lambda x: shingling_jaccard_similarity(tweet_df.loc[220].text, x, 3))\n",
    "tweet_df.sort_values('sim', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a57826ac1527eb1ce07a74d351c8176e",
     "grade": false,
     "grade_id": "cell-720ddb543dd9aef7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#TopListAngels 👠 Ready For BO 👠 🍭 @malangangels 🍭 🍸 Malang 🍸 💰 dan ☎ by DM https://t.co/vS1Oukm3yq\n",
      "RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭 @malangangels 🍭 🍸 Malang 🍸 💰 dan ☎ by DM https://t.co/dV3ibBQhar\n",
      "RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭 @malangvhi 🍭 🍸 Malang 🍸 💰 dan ☎ by DM https://t.co/tyqGu1id2S\n",
      "RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭 @KimiMlg 🍭 🍸 Malang 🍸 💰 dan ☎ by DM https://t.co/1SIagPPTAP\n",
      "#TopListAngels 👠 Ready For BO 👠 🍭 @VaniaBDG_2 🍭 🍸 Bandung 🍸 💰 dan ☎ by DM https://t.co/82ZT2nv2Py\n",
      "#TopListAngels 👠 Ready For BO 👠 🍭 @Lanci_Mevita 🍭 🍸 Expo Cirebon 🍸 💰 dan ☎ by DM https://t.co/KCyJE4cqH3\n",
      "RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭 @AmorPutri96 🍭 🍸 Bandung 🍸 💰 dan ☎ by DM https://t.co/GHNSo7Qc1U\n",
      "RT @dunk_sl: #TopListAngels 👠 Ready For BO 👠 🍭 @AmorPutri96 🍭 🍸 Bandung 🍸 💰 dan ☎ by DM https://t.co/XeNo4Dal2A\n",
      "Case of the Monday Blues? Nothing a KNOW Better cookie &amp; cup of joe can't fix.🍪 ☕️ #CookiesandCoffee #yummy\n",
      "RT @LunnMiss: #TwinPeaks 🌲🦉🌲 «Fire Walk With Me» Аrt.Dan May @Kyle_MacLachlan ☕️🥧☕️ @mfrost11🔥💔🔥 @DAVID_LYNCH @LynchFoundation https://…\n"
     ]
    }
   ],
   "source": [
    "near_dups = tweet_df.sort_values('sim', ascending=False).head(10)\n",
    "for x in list(near_dups.text):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dffc47f20e7d27530ad4d5c600970aaa",
     "grade": false,
     "grade_id": "cell-74a2bc16218167e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Indeed, we see that the top-8 Tweets look very similar! In fact, many of them are Retweets of the original Tweet, with only small variations on the user handler and/or URLs - so they are indeed near-duplicates. This concludes this assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
